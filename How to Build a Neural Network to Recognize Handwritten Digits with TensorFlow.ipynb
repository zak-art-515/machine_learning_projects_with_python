{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Goal:*** Use Tensorflow to build and train a neural\n",
    "network to recognize and predict the correct label for the digit displayed ( from 0 to 9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing the MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we will be using in this tutorial is called the MNIST dataset, this dataset is made up of images of handwritten digits, 28x28 pixels in size. Here are some examples of the digits included in the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import tensorflow library first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then import MNIST dataset that is available on tensorflow library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When reading in the data, we are using one-hot-encoding to represent the labels. One-hotencoding uses a vector of binary values to represent numeric or categorical values. One of these values is set to 1, to represent the digit at that index of the vector, and the rest are set to 0. For example, the digit 3 is represented using the vector [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-db8b451072c0>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\zakar\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\zakar\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\zakar\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\zakar\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\zakar\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\zakar\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True) # y labels are one-hot-encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is splited into 55,000 images for training, 5000 for validation, and 10,000 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train: 55000\n",
      "n_validation: 5000\n",
      "n_test: 10000\n"
     ]
    }
   ],
   "source": [
    "n_train = mnist.train.num_examples # 55,000\n",
    "n_validation = mnist.validation.num_examples # 5000\n",
    "n_test = mnist.test.num_examples # 10,000\n",
    "print (\"n_train:\", n_train)\n",
    "print (\"n_validation:\", n_validation)\n",
    "print (\"n_test:\", n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will store the number of units per layer in global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784 # input layer (28x28 pixels)\n",
    "n_hidden1 = 512 # 1st hidden layer\n",
    "n_hidden2 = 256 # 2nd hidden layer\n",
    "n_hidden3 = 128 # 3rd hidden layer\n",
    "n_output = 10 # output layer (0-9 digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters definition:\n",
    "* ***The learning rate*** represents how much the parameters will adjust at each step of the learning process.\n",
    "* ***The number of iterations*** refers to how many times we go through the training step.\n",
    "* ***Batch size refers*** to how many training examples we are using at each step.\n",
    "* ***Dropout*** give each unit a 50% chance of being eliminated at every training step. This helps prevent overfitting and reduce complexity of our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "n_iterations = 1000\n",
    "batch_size = 128 # mini-batches size\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Building the TensorFlow Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core concept of **TensorFlow** is the tensor, a data structure similar to an array or list. initialized, manipulated as they are passed through the graph, and updated through the learning process. We’ll start by defining three tensors as placeholders, which are tensors that we’ll feed values into later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_output])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaration as variables and Initialization of weights and biases of neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'w1':tf.Variable(tf.truncated_normal([n_input, n_hidden1],stddev = 0.1)),\n",
    "    'w2':tf.Variable(tf.truncated_normal([n_hidden1, n_hidden2],stddev = 0.1)),\n",
    "    'w3':tf.Variable(tf.truncated_normal([n_hidden2, n_hidden3],stddev = 0.1)),\n",
    "    'out':tf.Variable(tf.truncated_normal([n_hidden3, n_output],stddev = 0.1))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1' : tf.Variable(tf.constant(0.1, shape = [n_hidden1])),\n",
    "    'b2' : tf.Variable(tf.constant(0.1, shape = [n_hidden2])),\n",
    "    'b3' : tf.Variable(tf.constant(0.1, shape = [n_hidden3])),\n",
    "    'out' : tf.Variable(tf.constant(0.1, shape = [n_output]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of different operations that will manipulate the tensors through layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-b105da30796d>:4: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "layer_1 = tf.add(tf.matmul(X, weights['w1']),biases['b1'])\n",
    "layer_2 = tf.add(tf.matmul(layer_1, weights['w2']),biases['b2'])\n",
    "layer_3 = tf.add(tf.matmul(layer_2, weights['w3']),biases['b3'])\n",
    "layer_drop = tf.nn.dropout(layer_3, keep_prob)\n",
    "output_layer = tf.add(tf.matmul(layer_3, weights['out']),biases['out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the loss function. We will use **cross-entropy** or **log-loss** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-ece7cfe4ea63>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=Y, logits = output_layer\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of Optimization algorithm: Using **Adam Optimizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition **evaluation method** of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(output_layer,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The essence of the training process in deep learning is to optimize the loss function. Here we are aiming to minimize the difference between the predicted labels of the images, and the true labels of the images. The process involves four steps which are repeated for a set number of iterations:\n",
    "* Propagate values forward through the network;\n",
    "* Compute the loss;\n",
    "* Propagate values backward through the network;\n",
    "* Update the parameters.\n",
    "    \n",
    "At each training step, the parameters are adjusted slightly to try and reduce the loss for the next step. As the learning progresses, we should see a reduction in loss, and eventually we can stop training and use the network as a model for testing our new data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 \t| Loss = 3.634748 \t| Accuracy = 0.1640625\n",
      "Iteration 100 \t| Loss = 0.45517892 \t| Accuracy = 0.890625\n",
      "Iteration 200 \t| Loss = 0.4856335 \t| Accuracy = 0.84375\n",
      "Iteration 300 \t| Loss = 0.44947112 \t| Accuracy = 0.875\n",
      "Iteration 400 \t| Loss = 0.3840907 \t| Accuracy = 0.8515625\n",
      "Iteration 500 \t| Loss = 0.2897442 \t| Accuracy = 0.9140625\n",
      "Iteration 600 \t| Loss = 0.3297691 \t| Accuracy = 0.9140625\n",
      "Iteration 700 \t| Loss = 0.31791586 \t| Accuracy = 0.90625\n",
      "Iteration 800 \t| Loss = 0.2644313 \t| Accuracy = 0.921875\n",
      "Iteration 900 \t| Loss = 0.3957845 \t| Accuracy = 0.90625\n"
     ]
    }
   ],
   "source": [
    "# train on mini-batches\n",
    "for i in range(n_iterations):\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    sess.run(train_step, feed_dict = {\n",
    "        X: batch_x, Y: batch_y, keep_prob: dropout\n",
    "    })\n",
    "    # print loss and accuracy (per minibatch of 100 examples)\n",
    "    if i % 100 == 0:\n",
    "        minibatch_loss, minibatch_accuracy = sess.run([cross_entropy, accuracy], feed_dict = {X: batch_x, Y: batch_y, keep_prob:1.0})\n",
    "        print(\n",
    "            \"Iteration\",\n",
    "            str(i),\n",
    "            \"\\t| Loss =\",\n",
    "            str(minibatch_loss),\n",
    "            \"\\t| Accuracy =\",\n",
    "            str(minibatch_accuracy)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on test set: 0.9154\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = sess.run(accuracy, feed_dict = {X: mnist.test.images, Y : mnist.test.labels, keep_prob: 1.0})\n",
    "\n",
    "print(\"\\nAccuracy on test set:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our model on single image of our own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should first create the test image using paint tool of Windows or write with hands a digit and then take a photo. After that upload image on working directory. You can get working directory using ***pwd*** command in python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load and test image of the handwritten digit\n",
    "img = np.invert(Image.open(\"tensorflow-demo/test_image.png\").resize((28,28)).convert('L')).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for test image: 6\n"
     ]
    }
   ],
   "source": [
    "prediction = sess.run(tf.argmax(output_layer, 1), feed_dict = {X: [img]})\n",
    "print (\"Prediction for test image:\", np.squeeze(prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
